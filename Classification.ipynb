{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iai/user/blatt/myconda/bigenv/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'arch-forest/data/adult/adult.train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-176f3b79b7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataSet\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adult'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureGenerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadDataAdult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureGenerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadDataAdult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataSet\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'spambase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iai/user/blatt/PruningDistinctBranchingConditions/FeatureGenerators/ReadData.py\u001b[0m in \u001b[0;36mreadDataAdult\u001b[0;34m(type)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"adult/adult.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'arch-forest/data/adult/adult.train'"
     ]
    }
   ],
   "source": [
    "#load_ext line_profiler\n",
    "\n",
    "import csv,operator,sys,os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import json\n",
    "import FeatureGenerators.ReadData\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "sys.path.append('arch-forest/data/adult/')\n",
    "sys.path.append('arch-forest/data/bank/')\n",
    "sys.path.append('arch-forest/data/wine-quality/')\n",
    "sys.path.append('arch-forest/data/')\n",
    "sys.path.append('arch-forest/code/')\n",
    "import trainForest\n",
    "import Tree\n",
    "import FeatureGenerators.DecisionSnippetFeatures\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dataPath = \"arch-forest/data/\"\n",
    "frequentTreesPath = \"forests/rootedFrequentTrees/\"\n",
    "resultsPath = \"forests/rootedFrequentTrees/\"\n",
    "\n",
    "\n",
    "\n",
    "#import train data\n",
    "from FeatureGenerators.ReadData import readDataAdult,readDataBank, readWine, readWineTest, readDataSpambase, readDataMagic,readDataCovertype, readDataMnist, readDataSatlog, readDataSensorlessDrive\n",
    "\n",
    "dataSet='adult'\n",
    "\n",
    "if (dataSet == 'adult'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataAdult('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataAdult('test')\n",
    "if (dataSet == 'spambase'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataSpambase('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataSpambase('test')        \n",
    "if (dataSet == 'letter'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataLetter('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataLetter('test')  \n",
    "if (dataSet == 'bank'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataBank('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataBank('test')\n",
    "if (dataSet == 'magic'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataMagic('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataMagic('test')\n",
    "if (dataSet == 'covertype'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataCovertype('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataCovertype('test') \n",
    "if (dataSet == 'mnist'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataMnist('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataMnist('test')    \n",
    "if (dataSet == 'satlog'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataSatlog('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataSatlog('test')\n",
    "if (dataSet == 'sensorless-drive'):\n",
    "    X_train,Y_train = FeatureGenerators.ReadData.readDataSensorlessDrive('train')\n",
    "    X_test,Y_test = FeatureGenerators.ReadData.readDataSensorlessDrive('test')     \n",
    "if (dataSet == 'wine-quality'):\n",
    "        X_train,Y_train = FeatureGenerators.ReadData.readWine()\n",
    "        #X_test,Y_test = ReadData.readWineTest()\n",
    "print(len(X_test))\n",
    "\n",
    "\n",
    "# Classification\n",
    "\n",
    "results_list = []\n",
    "time_list = []\n",
    "rf_depth = 5\n",
    "scoring_function = 'accuracy'\n",
    "pattern_max_size=6\n",
    "variant = 'NoLeafEdgesWithSplitValue'\n",
    "\n",
    "start_time = time.time()\n",
    "model = GaussianNB()\n",
    "normalfeatures_nb_cv_score = cross_val_score(model, X_train, Y_train, cv=5, scoring=scoring_function)\n",
    "normal_time = time.time() - start_time\n",
    "normal_score = normalfeatures_nb_cv_score.mean()\n",
    "print('normal: '+str(normal_score))\n",
    "\n",
    "start_time = time.time()\n",
    "model = DecisionTreeClassifier(max_depth=rf_depth)\n",
    "dt_cv_score = cross_val_score(model, X_train, Y_train, cv=5, scoring=scoring_function)\n",
    "dt_time = time.time() - start_time\n",
    "dt_score = dt_cv_score.mean()\n",
    "print('DT: '+str(dt_score))\n",
    "    \n",
    "start_time = time.time()    \n",
    "model = RandomForestClassifier(max_depth=rf_depth, n_estimators=100)\n",
    "rf_cv_score = cross_val_score(model, X_train, Y_train, cv=5, scoring=scoring_function)\n",
    "rf_time = time.time() - start_time\n",
    "rf_score = rf_cv_score.mean()\n",
    "print('RF: '+str(rf_score))\n",
    "\n",
    "for rf_depth in (5,10,15,20):\n",
    "    \n",
    "    for frequency in range(2,26):\n",
    "        \n",
    "        for pruning in ['', '0_0', '0_1', '0_2', '0_3']:\n",
    "            if pruning == '':\n",
    "                pruning_str = ''\n",
    "            else:\n",
    "                pruning_str = \"_pruned_with_sigma_\"+pruning\n",
    "        \n",
    "            start_time = time.time()\n",
    "            rootedFrequentTrees = \"RF_\"+str(rf_depth)+pruning_str+\"_t\"+str(frequency)\n",
    "            f = open(frequentTreesPath+dataSet+'/'+variant+'/leq'+str(pattern_max_size)+'/'+rootedFrequentTrees+'.json')\n",
    "            frequentpatterns = json.load(f)\n",
    "            f.close()\n",
    "\n",
    "            if (frequency < 4):\n",
    "\n",
    "\n",
    "                dsf = FeatureGenerators.DecisionSnippetFeatures.FrequentSubtreeFeatures(map(lambda x: x['pattern'], frequentpatterns[-100:]))\n",
    "                #dsf = DecisionSnippetFeatures.FrequentSubtreeFeatures(frequentpatterns)\n",
    "\n",
    "\n",
    "                fts = dsf.fit_transform(X_train,0)\n",
    "                fts_test = dsf.fit_transform(X_test,0)\n",
    "                #print(fts)\n",
    "\n",
    "                from sklearn.preprocessing import OneHotEncoder\n",
    "                fts_onehot = OneHotEncoder(n_values=dsf.get_n_values()).fit_transform(fts)\n",
    "                fts_onehot_test = OneHotEncoder(n_values=dsf.get_n_values()).fit_transform(fts_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                model = KNeighborsClassifier(n_neighbors=25,metric='euclidean')\n",
    "                model.fit( fts_onehot.toarray(),Y_train)\n",
    "                y_pred = model.predict(fts_onehot_test.toarray())\n",
    "\n",
    "\n",
    "                dsf_score = model.score(fts_onehot_test.toarray(),Y_test)\n",
    "                dsf_time = time.time() - start_time\n",
    "\n",
    "\n",
    "            print('t'+str(frequency )+'_DSF: '+str(dsf_score))\n",
    "\n",
    "            #model = svm.SVC(kernel='linear',C=1.0)\n",
    "            '''\n",
    "            model = LinearSVC()\n",
    "            model.fit( fts_onehot.toarray(),Y_train)\n",
    "            y_pred = model.predict(fts_onehot_test.toarray())\n",
    "\n",
    "\n",
    "            dsf_score = model.score(fts_onehot_test.toarray(),Y_test)\n",
    "            dsf_time = time.time() - start_time\n",
    "            print('t'+str(frequency )+'_DSF: '+str(dsf_score))\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #print(fts_onehot.toarray()[0])\n",
    "            #print(fts_onehot_test.toarray()[0])\n",
    "\n",
    "            #model: Log Reg\n",
    "            '''model = LogisticRegression()\n",
    "            model.fit( fts_onehot.toarray(),Y_train)\n",
    "            y_pred = model.predict(fts_onehot_test.toarray())\n",
    "\n",
    "\n",
    "            dsf_score = model.score(fts_onehot_test.toarray(),Y_test)\n",
    "            dsf_time = time.time() - start_time\n",
    "            print('t'+str(frequency )+'_DSF: '+str(dsf_score))\n",
    "            #for i in range (0,20):\n",
    "            #   print(Y_test[i])\n",
    "            #    print(y_pred[i])\n",
    "            '''\n",
    "\n",
    "            #y_pred = model.predict(fts_onehot_test.toarray())\n",
    "            #conf_mat = confusion_matrix(Y_test,y_pred)\n",
    "            #print(conf_mat)\n",
    "            #print(classification_report(Y_test,y_pred))\n",
    "\n",
    "\n",
    "            #model = GaussianNB()\n",
    "            #fts_onehot_nb_cv_score = cross_val_score(model, fts_onehot.toarray(), Y_train, cv=5, scoring=scoring_function)\n",
    "            #dsf_time = time.time() - start_time\n",
    "            #print(fts_onehot_nb_cv_score)\n",
    "            #dsf_score = fts_onehot_nb_cv_score.mean()\n",
    "            #print('t'+str(frequency )+'_DSF: '+str(dsf_score))\n",
    "\n",
    "\n",
    "\n",
    "            result = \"t\"+str(frequency)+\",\"+str(dsf_score)+\",\"+str(normal_score)+\",\"+str(dt_score)+\",\"+str(rf_score)+\",\\n\"\n",
    "            results_list.append(result)\n",
    "            times = \"t\"+str(frequency)+\",\"+str(dsf_time)+\",\"+str(normal_time)+\",\"+str(dt_time)+\",\"+str(rf_time)+\",\\n\"\n",
    "            time_list.append(times)\n",
    "\n",
    "    f= open(resultsPath+dataSet+'/Results_'+variant+'/leq'+str(pattern_max_size)+'/'+'RF_'+str(rf_depth)+'_'+scoring_function+'_KNN.csv',\"a\")\n",
    "    for line in results_list:\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "\n",
    "    f= open(resultsPath+dataSet+'/Results_'+variant+'/leq'+str(pattern_max_size)+'/'+'RF_'+str(rf_depth)+'_'+scoring_function+'_time_KNN.csv',\"a\")\n",
    "    for line in time_list:\n",
    "        f.write(line)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
