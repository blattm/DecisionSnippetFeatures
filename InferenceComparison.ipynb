{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iai/user/adams0/myconda/bigenv/lib/python3.8/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../arch-forest/data/adult/adult.train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-99fbca2356e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adult'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadDataAdult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadDataAdult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'spambase'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iai/user/adams0/PruningDistinctBranchingConditions/FeatureGenerators/ReadData.py\u001b[0m in \u001b[0;36mreadDataAdult\u001b[0;34m(type)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"adult/adult.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../arch-forest/data/adult/adult.train'"
     ]
    }
   ],
   "source": [
    "\n",
    "# set dataset name and run, the output results file and plot are exported to the folder InferenceComparison/  \n",
    "dataset='adult'\n",
    "\n",
    "import csv,operator,sys,os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import json\n",
    "import FeatureGenerators.ReadData as ReadData\n",
    "import time\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('arch-forest/data/adult/')\n",
    "sys.path.append('arch-forest/data/bank/')\n",
    "sys.path.append('arch-forest/data/wine-quality/')\n",
    "sys.path.append('arch-forest/data/')\n",
    "sys.path.append('arch-forest/code/')\n",
    "import trainForest\n",
    "import Tree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import FeatureGenerators.DecisionSnippetFeatures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filesPath = \"arch-forest/data/\"\n",
    "frequentTreesPath = \"forests/rootedFrequentTrees/\"\n",
    "comparisonCountPath = \"InferenceComparison/\"\n",
    "\n",
    "from FeatureGenerators.ReadData import readDataAdult,readWine, readWineTest\n",
    "\n",
    "if (dataset == 'adult'):\n",
    "    X_train,Y_train = ReadData.readDataAdult('train')\n",
    "    X_test,Y_test = ReadData.readDataAdult('test')\n",
    "if (dataset == 'spambase'):\n",
    "    X_train,Y_train = ReadData.readDataSpambase('train')\n",
    "    X_test,Y_test = ReadData.readDataSpambase('test')\n",
    "if (dataset == 'wine-quality'):\n",
    "        X_train,Y_train = ReadData.readWine()\n",
    "        X_test,Y_test = ReadData.readWineTest()\n",
    "if (dataset == 'letter'):\n",
    "    X_train,Y_train = ReadData.readDataLetter('train')\n",
    "    X_test,Y_test = ReadData.readDataLetter('test')    \n",
    "print(len(X_train))\n",
    "\n",
    "# Classification\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "    \n",
    "import FeatureGenerators.DecisionSnippetFeatures\n",
    "\n",
    "results_list = []\n",
    "time_list = []\n",
    "rf_depth = 5\n",
    "scoring_function = 'accuracy'\n",
    "pattern_max_size=6\n",
    "variant = 'NoLeafEdgesWithSplitValues'\n",
    "\n",
    "countsList =[]\n",
    "\n",
    "for rf_depth in (5,10,15,20):\n",
    "  for frequency in range(2,26,1):\n",
    "    \n",
    "    \n",
    "    rootedFrequentTrees = \"RF_\"+str(rf_depth)+\"_t\"+str(frequency)\n",
    "    f = open(frequentTreesPath+dataset+'/'+variant+'/leq'+str(pattern_max_size)+'/'+rootedFrequentTrees+'.json')\n",
    "    frequentpatterns = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    dsf = FeatureGenerators.DecisionSnippetFeatures.FrequentSubtreeFeatures(map(lambda x: x['pattern'], frequentpatterns[-200:])) \n",
    "\n",
    "    fts = dsf.fit_transform(X_test,1)\n",
    "\n",
    "    compareCount = 0\n",
    "    for i in range(0,len(X_test)):\n",
    "        for nodesNumber in fts[i]:\n",
    "            compareCount += nodesNumber\n",
    "    \n",
    "    \n",
    "    print(round(compareCount/len(X_test),1))\n",
    "    countsList.append('RF_'+str(rf_depth)+'_t'+str(frequency)+','+str(round(compareCount/len(X_test),1))+',\\n')\n",
    "\n",
    "# Complete\n",
    "\n",
    "for rf_depth in (5,10,15,20):\n",
    "    \n",
    "    f = open(comparisonCountPath+'/'+dataSet+'/'+'RF_'+str(rf_depth)+'.json')\n",
    "    frequentpatterns = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    dsf = FeatureGenerators.DecisionSnippetFeatures.FrequentSubtreeFeatures(map(lambda x: x['pattern'], frequentpatterns[-200:]))  \n",
    "\n",
    "    fts = dsf.fit_transform(X_test,1)\n",
    "\n",
    "    compareCount = 0\n",
    "    for i in range(0,len(X_test)):\n",
    "        for nodesNumber in fts[i]:\n",
    "            compareCount += nodesNumber\n",
    "    \n",
    "    \n",
    "    print(round(compareCount/len(X_test)))\n",
    "    countsList.append('RF_'+str(rf_depth)+','+str(round(compareCount/len(X_test),1))+',\\n')    \n",
    "    \n",
    "\n",
    "\n",
    "file= open(comparisonCountPath+'/'+dataSet+'/'+dataSet+'_comparisons_count.csv',\"w\")\n",
    "for count in countsList:\n",
    "    file.write(count)\n",
    "\n",
    "\n",
    "file.close()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "accuracy_list = []\n",
    "accuracy_list_rf = []\n",
    "count_list = []\n",
    "size_list_rf = []\n",
    "rf_list = []\n",
    "\n",
    "\n",
    "\n",
    "with open(comparisonCountPath+'/'+dataset+'/'+dataset+'_comparisons_count'+'.csv') as count_file:\n",
    "        count_reader = csv.reader(count_file, delimiter='\\n')\n",
    "        line_count = 1\n",
    "        for row in count_reader:\n",
    "            if (line_count > 1 ):\n",
    "                \n",
    "                rowStr = str(row).split(',')                                       \n",
    "                count_list.append(rowStr[1])\n",
    "            line_count +=1    \n",
    "\n",
    "count_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for rf_depth in (5,10,15,20):\n",
    "    \n",
    "    f = open(comparisonCountPath+'/'+dataset+'/'+'RF_'+str(rf_depth)+'.json')\n",
    "    frequentpatterns = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    dsf = FeatureGenerators.DecisionSnippetFeatures.FrequentSubtreeFeatures(map(lambda x: x['pattern'], frequentpatterns[-200:]))  \n",
    "\n",
    "    fts = dsf.fit_transform(X_test,1)\n",
    "\n",
    "    compareCount = 0\n",
    "    for i in range(0,len(X_test)):\n",
    "        for nodesNumber in fts[i]:\n",
    "            compareCount += nodesNumber\n",
    "    \n",
    "    \n",
    "    print(round(compareCount/len(X_test)))\n",
    "    countsList.append('RF_'+str(rf_depth)+','+str(round(compareCount/len(X_test),1))+',\\n')    \n",
    "    \n",
    "\n",
    "\n",
    "file= open(comparisonCountPath+'/'+dataset+'/'+dataset+'_comparisons_count.csv',\"w\")\n",
    "for count in countsList:\n",
    "    file.write(count)\n",
    "\n",
    "\n",
    "file.close()\n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "accuracy_list = []\n",
    "accuracy_list_rf = []\n",
    "count_list = []\n",
    "size_list_rf = []\n",
    "rf_list = []\n",
    "\n",
    "\n",
    "\n",
    "with open(comparisonCountPath+'/'+dataset+'/'+dataset+'_comparisons_count'+'.csv') as count_file:\n",
    "        count_reader = csv.reader(count_file, delimiter='\\n')\n",
    "        #line_count = 1\n",
    "        for row in count_reader:\n",
    "            #if (line_count > 1 ):\n",
    "                \n",
    "                rowStr = str(row).split(',')                                       \n",
    "                count_list.append(rowStr[1])\n",
    "            #line_count +=1    \n",
    "\n",
    "count_file.close()\n",
    "\n",
    "\n",
    "\n",
    "for rf_depth in (5,10,15,20):\n",
    "    \n",
    "    with open(frequentTreesPath+'/'+dataset+'/Results_'+variant+'/leq'+str(pattern_max_size)+'/'+'RF_'+str(rf_depth)+'_'+scoring_function+'.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter='\\n')\n",
    "        line_count = 2\n",
    "        for row in csv_reader:\n",
    "            rowStr = str(row).split(',')\n",
    "            if line_count < 26:\n",
    "                accuracy_list.append(rowStr[1])\n",
    "                rf_list.append('RF_'+str(rf_depth)+'_t'+str(line_count))\n",
    "                if (line_count == 5):\n",
    "                    accuracy_list_rf.append(rowStr[4])\n",
    "                line_count+=1\n",
    "    csv_file.close()\n",
    "    \n",
    "print(len(rf_list))\n",
    "print(len(count_list))\n",
    "print(len(accuracy_list))\n",
    "    \n",
    "f= open(comparisonCountPath+'/'+dataset+'/'+'comparisons_count_vs_accuracy_'+dataset+'_'+variant+'_leq'+str(pattern_max_size)+'.csv',\"w\")\n",
    "f.write('RF,comparisons Count,accuracy,\\n')\n",
    "for i in range(0,len(accuracy_list)):\n",
    "        f.write(rf_list[i]+','+count_list[i]+','+accuracy_list[i]+',\\n')\n",
    "for depth in (5,10,15,20):\n",
    "        f.write('RF_'+str(depth)+','+count_list[int(depth/5) +len(accuracy_list)-1]+','+accuracy_list_rf[int(depth/5) -1]+',\\n')\n",
    "f.close()\n",
    "\n",
    "\n",
    "#print(len(accuracy_list))\n",
    "#for i in range(0,len(count_list)):\n",
    "#        print(rf_list[i]+'\\n')\n",
    "\n",
    "\n",
    "accuracy_list_dsf = []\n",
    "count_list_dsf = []\n",
    "accuracy_list = []\n",
    "count_list = []\n",
    "\n",
    "\n",
    "with open(comparisonCountPath+'/'+dataset+'/'+'comparisons_count_vs_accuracy_'+dataset+'_'+variant+'_leq'+str(pattern_max_size)+'.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter='\\n')\n",
    "        lineCount =1    \n",
    "            \n",
    "        for row in csv_reader:\n",
    "                if (lineCount > 1 ):\n",
    "                    rowStr = str(row).split(',')\n",
    "                    if (lineCount > 97):\n",
    "                        count_list.append(rowStr[1])\n",
    "                        accuracy_list.append(rowStr[2])\n",
    "                    else:\n",
    "                        count_list_dsf.append(rowStr[1])\n",
    "                        accuracy_list_dsf.append(rowStr[2])\n",
    "                        \n",
    "            \n",
    "                    \n",
    "                lineCount+=1\n",
    "                \n",
    "            \n",
    "                \n",
    "csv_file.close()\n",
    "\n",
    "\n",
    "\n",
    "count = np.array(count_list, dtype=np.float32)\n",
    "accuracy = np.array(accuracy_list, dtype=np.float32)\n",
    "\n",
    "count_dsf = np.array(count_list_dsf, dtype=np.float32)\n",
    "accuracy_dsf = np.array(accuracy_list_dsf, dtype=np.float32)\n",
    "\n",
    "####\n",
    "best_dsf_rf5 = 0\n",
    "best_dsf_rf10 = 0\n",
    "best_dsf_rf15 = 0\n",
    "best_dsf_rf20 = 0\n",
    "best_dsf_rf5_index = 0\n",
    "best_dsf_rf10_index = 0\n",
    "best_dsf_rf15_index = 0\n",
    "best_dsf_rf20_index = 0\n",
    "\n",
    "for i in range(0,len(count_dsf)):\n",
    "    if (i < 24):\n",
    "        if (accuracy_dsf[i] > best_dsf_rf5):\n",
    "            best_dsf_rf5 = accuracy_dsf[i]\n",
    "            best_dsf_rf5_index = i\n",
    "    if (i >= 24 and i < 48):\n",
    "        if (accuracy_dsf[i] > best_dsf_rf10):\n",
    "            best_dsf_rf10 = accuracy_dsf[i]\n",
    "            best_dsf_rf10_index = i    \n",
    "    if (i >= 48 and i < 72):\n",
    "        if (accuracy_dsf[i] > best_dsf_rf15):\n",
    "            best_dsf_rf15 = accuracy_dsf[i]\n",
    "            best_dsf_rf15_index = i\n",
    "    if (i >= 72 and i < 96):\n",
    "        if (accuracy_dsf[i] > best_dsf_rf20):\n",
    "            best_dsf_rf20 = accuracy_dsf[i]\n",
    "            best_dsf_rf20_index = i        \n",
    "    \n",
    "\n",
    "accuracy_dsf_best = []\n",
    "accuracy_dsf_best.append(best_dsf_rf5)\n",
    "accuracy_dsf_best.append(best_dsf_rf10)\n",
    "accuracy_dsf_best.append(best_dsf_rf15)\n",
    "accuracy_dsf_best.append(best_dsf_rf20)\n",
    "count_dsf_best = []\n",
    "count_dsf_best.append(count_dsf[best_dsf_rf5_index])\n",
    "count_dsf_best.append(count_dsf[best_dsf_rf10_index])\n",
    "count_dsf_best.append(count_dsf[best_dsf_rf15_index])\n",
    "count_dsf_best.append(count_dsf[best_dsf_rf20_index])\n",
    "\n",
    "for i in range(0,len(count)):\n",
    "    plt.scatter(count[i], accuracy[i], c='red')\n",
    "    plt.text(count[i], accuracy[i]-0.005, (i+1)*5, fontsize=9)\n",
    "    plt.scatter(count_dsf_best[i], accuracy_dsf_best[i], c='blue')\n",
    "    plt.text(count_dsf_best[i], accuracy_dsf_best[i]-0.005, (i+1)*5, fontsize=9)\n",
    "\n",
    "\n",
    "#####\n",
    "#plt.scatter(count, accuracy, c='lightblue')\n",
    "#plt.scatter(count_dsf, accuracy_dsf, c='red')\n",
    "\n",
    "\n",
    "plt.xlabel('Comparisons Count')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.60, box.height])\n",
    "plt.legend(['Complete RF','DSF'],bbox_to_anchor=(1.0, 0.5), loc='upper left')\n",
    "plt.text(27, 0.77, '')\n",
    "fig = plt.gcf()\n",
    "fig.savefig(comparisonCountPath+'comparisons_count_'+dataset+'_'+variant+'_'+scoring_function+'.png', dpi=150)\n",
    "fig.show()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
